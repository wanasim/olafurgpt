# The Llama Cloud API key.
# LLAMA_CLOUD_API_KEY=

# The provider for the AI models to use.
MODEL_PROVIDER=openai

# The name of LLM model to use.
MODEL=gpt-3.5-turbo

# Name of the embedding model to use.
EMBEDDING_MODEL=text-embedding-3-large

# Dimension of the embedding model to use.
EMBEDDING_DIM=1024

# The questions to help users get started (multi-line).
# CONVERSATION_STARTERS=

# The OpenAI API key to use.
# OPENAI_API_KEY=

# Temperature for sampling from the model.
# LLM_TEMPERATURE=

# Maximum number of tokens to generate.
# LLM_MAX_TOKENS=

# The number of similar embeddings to return when retrieving documents.
TOP_K=3

# The time in milliseconds to wait for the stream to return a response.
STREAM_TIMEOUT=60000

# For generating a connection URI, see https://docs.timescale.com/use-timescale/latest/services/create-a-service
# The PostgreSQL connection string.
# PG_CONNECTION_STRING=

# FILESERVER_URL_PREFIX is the URL prefix of the server storing the images generated by the interpreter.
FILESERVER_URL_PREFIX=http://localhost:3000/api/files

# The system prompt for the AI model.
SYSTEM_PROMPT="You are a DuckDuckGo search agent. 
You can use the duckduckgo search tool to get information from the web to answer user questions.
For better results, you can specify the region parameter to get results from a specific region but it's optional.
You are a Wikipedia agent. You help users to get information from Wikipedia.
You are an OpenAPI action agent. You help users to make requests to the provided OpenAPI schema.
"

